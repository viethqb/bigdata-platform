# Generated by Apache Ambari. Sat Apr  8 18:04:34 2023
#spark.jars.packages io.delta:delta-core_2.12:2.3.0
spark.sql.extensions io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog org.apache.spark.sql.delta.catalog.DeltaCatalog   
spark.databricks.delta.schema.autoMerge.enabled true 
spark.driver.extraClassPath  
#spark.driver.extraLibraryPath /usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64
spark.eventLog.dir s3a://spark-history/logs/
spark.eventLog.enabled true
spark.executor.extraJavaOptions -XX:+UseNUMA
#spark.executor.extraLibraryPath /usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64
spark.extraListeners  
spark.history.fs.cleaner.enabled true
spark.history.fs.cleaner.interval 7d
spark.history.fs.cleaner.maxAge 90d
spark.history.fs.logDirectory s3a://spark-history/logs/
spark.history.kerberos.keytab none
spark.history.kerberos.principal none
spark.history.provider org.apache.hadoop.fs.s3a.S3AFileSystem
spark.history.store.path /var/lib/spark2/shs_db
spark.history.ui.port 18081
spark.io.compression.lz4.blockSize 128kb
#spark.master yarn
spark.shuffle.file.buffer 1m
spark.shuffle.io.backLog 8192
spark.shuffle.io.serverThreads 128
spark.shuffle.unsafe.file.output.buffer 5m
spark.sql.autoBroadcastJoinThreshold 26214400
spark.sql.hive.convertMetastoreOrc true
#spark.sql.hive.metastore.jars /usr/hdp/current/spark2-client/standalone-metastore/*
#spark.sql.hive.metastore.version 3.0
spark.sql.orc.filterPushdown true
spark.sql.orc.impl native
spark.sql.queryExecutionListeners  
spark.sql.statistics.fallBackToHdfs true
spark.sql.streaming.streamingQueryListeners  
spark.sql.warehouse.dir /apps/spark/warehouse
spark.unsafe.sorter.spill.reader.buffer.size 1m
#spark.yarn.dist.files  
#spark.yarn.historyServer.address data1:18081
#spark.yarn.queue default
spark.hadoop.fs.s3a.access.key accesskey
spark.hadoop.fs.s3a.secret.key secretkey
spark.hadoop.fs.s3a.path.style.access true
spark.hadoop.fs.s3a.block.size 512M
spark.hadoop.fs.s3a.buffer.dir /tmp/s3a
spark.hadoop.fs.s3a.committer.magic.enabled false
spark.hadoop.fs.s3a.committer.name directory
spark.hadoop.fs.s3a.committer.staging.abort.pending.uploads true
spark.hadoop.fs.s3a.committer.staging.conflict-mode append
spark.hadoop.fs.s3a.committer.staging.tmp.path /tmp/staging
spark.hadoop.fs.s3a.committer.staging.unique-filenames true
spark.hadoop.fs.s3a.committer.threads 2048
spark.hadoop.fs.s3a.connection.establish.timeout 5000
spark.hadoop.fs.s3a.connection.maximum 8192
spark.hadoop.fs.s3a.connection.ssl.enabled false
spark.hadoop.fs.s3a.connection.timeout 200000
spark.hadoop.fs.s3a.endpoint http://minio:9000
spark.hadoop.fs.s3a.fast.upload.active.blocks 2048
spark.hadoop.fs.s3a.fast.upload.buffer disk
spark.hadoop.fs.s3a.fast.upload true
spark.hadoop.fs.s3a.impl org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.max.total.tasks 2048
spark.hadoop.fs.s3a.multipart.size 512M
spark.hadoop.fs.s3a.multipart.threshold 512M
spark.hadoop.fs.s3a.socket.recv.buffer 65536
spark.hadoop.fs.s3a.socket.send.buffer 65536
spark.hadoop.fs.s3a.threads.max 2048
spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider 